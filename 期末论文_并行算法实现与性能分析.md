# 并行算法实现与性能分析

**课程项目报告**

**日期：** 2025年12月24日

---

## 目录

1. [神经网络算子并行化](#1-神经网络算子并行化)
   - 1.1 [卷积算子(Conv2d)](#11-卷积算子conv2d)
   - 1.2 [平均池化算子(AvgPool2d)](#12-平均池化算子avgpool2d)
2. [红黑排序Gauss-Seidel迭代法](#2-红黑排序gauss-seidel迭代法)
3. [三对角方程组并行求解](#3-三对角方程组并行求解)

---

## 1. 神经网络算子并行化

神经网络中的算子计算通常具有高度的数据并行性，通过OpenMP等并行技术可以显著提升计算性能。本节介绍两个典型的神经网络算子：卷积（Convolution）和平均池化（Average Pooling）的并行实现。

### 1.0 计算密集型 vs 访存密集型

在并行计算中，算子的性能特征可以分为两类：

#### 1.0.1 计算密集型（Compute-Bound）

**定义：** 算法的性能瓶颈在于计算单元（ALU、FPU）的吞吐量，而非内存带宽。

**特征：**
- **高计算访存比（Compute-to-Memory Ratio）**：每次内存访问对应大量计算操作
- **算术强度大**：浮点运算次数 / 内存访问字节数 >> 1
- **瓶颈**：处理器的浮点运算能力
- **并行效果**：通常能获得较好的加速比

**典型例子：**
- **卷积操作**：每个输出元素需要 $C_{in} \times K_h \times K_w$ 次乘加运算
  - 对于5×5卷积，32输入通道：每个输出需要 $32 \times 5 \times 5 = 800$ 次乘加
  - 算术强度：$800 \text{ FLOP} / (800 \times 4 \text{ bytes}) \approx 0.25$ FLOP/byte
- **矩阵乘法**：$O(n^3)$ 计算量，$O(n^2)$ 内存访问

**优化策略：**
- 增加并行度（多线程、SIMD）
- 提高指令级并行（ILP）
- 循环展开、流水线优化

#### 1.0.2 访存密集型（Memory-Bound）

**定义：** 算法的性能瓶颈在于内存系统的带宽，而非计算能力。

**特征：**
- **低计算访存比**：每次内存访问对应很少的计算操作
- **算术强度小**：浮点运算次数 / 内存访问字节数 << 1
- **瓶颈**：内存带宽、缓存命中率
- **并行效果**：容易受内存带宽限制，加速比受限

**典型例子：**
- **池化操作**：每个输出元素只需要 $K_h \times K_w$ 次加法和1次除法
  - 对于2×2池化：4次加法 + 1次除法 = 5次操作
  - 算术强度：$5 \text{ FLOP} / (4 \times 4 \text{ bytes}) \approx 0.31$ FLOP/byte
- **Batch Normalization**：主要是内存读写和简单运算
- **激活函数**（ReLU等）：逐元素操作，计算量极小

**优化策略：**
- 提高缓存命中率（数据重用、分块）
- 减少内存访问次数
- 预取（Prefetch）优化
- 内存访问模式优化（连续访问、对齐）

#### 1.0.3 Roofline模型

性能上限由两个因素决定：

$$
\text{Performance} = \min(\text{Peak FLOPS}, \text{Arithmetic Intensity} \times \text{Memory Bandwidth})
$$

- **计算密集型**：接近Peak FLOPS（屋顶的水平部分）
- **访存密集型**：受限于Memory Bandwidth（屋顶的斜线部分）

**对并行化的影响：**

| 类型 | 并行加速比 | 主要挑战 | 优化重点 |
|------|----------|---------|--------|
| 计算密集型 | 接近线性 | 负载均衡 | 增加计算并行度 |
| 访存密集型 | 受限 | 内存带宽竞争 | 减少内存访问、提高缓存效率 |

---

### 1.1 卷积算子(Conv2d) - 计算密集型

#### 1.1.1 算法原理

二维卷积是深度学习中最基础且最重要的操作之一。给定输入特征图 $X \in \mathbb{R}^{C_{in} \times H_{in} \times W_{in}}$ 和卷积核 $W \in \mathbb{R}^{C_{out} \times C_{in} \times K_h \times K_w}$，卷积操作计算输出特征图 $Y \in \mathbb{R}^{C_{out} \times H_{out} \times W_{out}}$：

$$
Y[o, h, w] = b[o] + \sum_{c=0}^{C_{in}-1} \sum_{i=0}^{K_h-1} \sum_{j=0}^{K_w-1} X[c, h \cdot s_h + i, w \cdot s_w + j] \cdot W[o, c, i, j]
$$

其中：
- $C_{in}$, $C_{out}$: 输入和输出通道数
- $K_h$, $K_w$: 卷积核高度和宽度
- $s_h$, $s_w$: 步长(stride)
- $b[o]$: 偏置项

输出特征图的尺寸计算公式：

$$
H_{out} = \lfloor \frac{H_{in} + 2 \cdot padding - K_h}{s_h} \rfloor + 1
$$

$$
W_{out} = \lfloor \frac{W_{in} + 2 \cdot padding - K_w}{s_w} \rfloor + 1
$$

#### 1.1.2 实现细节

**串行实现：**
```cpp
    int pw = padded_mat.width;
    for (int i = 0; i < oc; ++i)
    {
        for (int d = 0; d < pd; ++d)
        {
            for (int c = 0; c < pc; ++c)
            {
                for (int h = 0; h < ph; h += conv_stride[0])
                {
                    if (h + conv_kernel_size[0] > ph)
                        continue;
                    for (int w = 0; w < pw; w += conv_stride[1])
                    {
                        if (w + conv_kernel_size[1] > pw)
                            continue;
                        int index = d * pc * ph * pw + c * ph * pw + h * pw + w;
                        sum = 0;
                        for (int i = 0; i < conv_kernel_max; ++i)
                        {
                            sum += (padded_mat[index + dx[i]] * weight[weight_pos + i]);
                        }
                        output[cnt[c]++] += sum;
                    }
                }
                weight_pos += conv_kernel_max;
            }
        }
    }
    for (int i = 0; i < output.channel; ++i)
    {
        for (int j = 0; j < output.height * output.width; ++j)
        {
            output[i * output.height * output.width + j] += bias[i];
        }
    }
```
**并行实现（初步）**
```cpp
#pragma omp parallel for
    for (int i = 0; i < output.channel; ++i)
    {
        for (int d = 0; d < padded_mat.dim; ++d)
        {
            for (int c = 0; c < padded_mat.channel; ++c)
            {
                int weight_pos = i * padded_mat.channel * conv_kernel_max + c * conv_kernel_max;
                for (int h = 0; h < input.height; h += conv_stride[0])
                {
                    for (int w = 0; w < input.width; w += conv_stride[1])
                    {
                        int index = d * padded_mat.channel * padded_mat.height * padded_mat.width + c * padded_mat.height * padded_mat.width + h * padded_mat.width + w;
                        int output_index = i * output.height * output.width + h * output.width + w;
                        for (int m = 0; m < conv_kernel_max; ++m)
                        {
                            output[output_index] += (padded_mat[index + dx[m]] * weight[weight_pos + m]);
                        }
                    }
                }
            }
        }
    }
    for (int i = 0; i < output.channel; ++i)
    {
        for (int j = 0; j < output.height * output.width; ++j)
        {
            output[i * output.height * output.width + j] += bias[i];
        }
    }
```



**并行优化策略：**

1. **Padding优化**：预先对输入进行padding，避免边界判断
   
   ```cpp
   Mat padd(const Mat input, int this_padding) {
       // 创建扩展后的矩阵
       Mat new_mat(input.dim, input.channel, 
                   input.height + 2*this_padding, 
                   input.width + 2*this_padding);
       // 填充零值并复制原始数据
       // ...
   }
   ```
   
2. **索引预计算**：对于固定大小的卷积核(3×3, 5×5)，预计算偏移量数组
   ```cpp
   int dx[25];  // 存储卷积核位置的偏移量
   // 对于5×5卷积核
   dx[0] = 0; dx[1] = 1; dx[2] = 2; dx[3] = 3; dx[4] = 4;
   dx[5] = width; dx[6] = width+1; ...
   ```

3. **OpenMP并行化**：在最外层循环（输出通道维度）添加并行指令
   ```cpp
   #pragma omp parallel for
   for (int oc = 0; oc < output_channels; ++oc) {
       // 卷积计算
   }
   ```
1.1.3
| 对比维度        | 串行实现                       | 并行实现（初步）                         | 影响                     |
| :-------------- | :----------------------------- | :--------------------------------------- | :----------------------- |
| **索引方式**    | 动态计数：`output[cnt[c]++]`   | 静态计算：`output[i*oh*ow + h*ow + w]`   | **并行化的基础变更**     |
| **weight\_pos** | 循环累加：`+= conv_kernel_max` | 公式计算：`i*pc*k + c*k`                 | 消除跨线程依赖           |
| **线程安全性**  | 单线程安全，多线程有数据竞争   | **batch>1时维度缺失**，batch=1时功能正确 | 存在逻辑错误             |
| **并行粒度**    | 无                             | 最外层 `output.channel` 并行             | 计算密集型算子的合理选择 |
| **性能隐患**    | 无                             | **伪共享**（False Sharing）              | 加速比不理想             |

#### 1.1.4 并行化难点分析

虽然卷积是计算密集型操作，但并行化仍面临诸多挑战：

**1. 内存访问模式复杂**

```
问题：卷积核的滑动窗口导致不连续的内存访问
影响：降低缓存命中率，增加内存延迟
```

- **输入重用**：相邻输出位置共享输入数据（重叠区域）
  - 例如：stride=1时，相邻输出共享 $(K_h-1) \times K_w$ 个输入
  - 但多线程并行时，不同线程访问的输入区域可能分散

- **权重重用**：所有输出位置共享同一组卷积核权重
  - 理想情况：权重常驻L1/L2缓存
  - 实际情况：多线程竞争缓存，可能导致抖动（thrashing）

**解决方案：**
```cpp
// 分块策略：将输出划分为小块，提高数据局部性
#pragma omp parallel for collapse(2)
for (int tile_h = 0; tile_h < H_out; tile_h += TILE_SIZE) {
    for (int tile_w = 0; tile_w < W_out; tile_w += TILE_SIZE) {
        // 在tile内部处理，提高输入和权重的重用
    }
}
```

**2. 负载不均衡**

```
问题：不同输出通道的计算量可能不同（如深度可分离卷积）
影响：部分线程提前完成，造成空闲等待
```

**解决方案：**
- 使用动态调度：`#pragma omp parallel for schedule(dynamic, chunk_size)`
- 但动态调度增加了调度开销

**3. False Sharing（伪共享）**

```
问题：不同线程写入同一缓存行的不同位置
影响：频繁的缓存一致性协议，严重降低性能
```

示例：
```cpp
// 错误：多个线程可能写入相邻的output位置，导致伪共享
#pragma omp parallel for
for (int oc = 0; oc < channels; ++oc) {
    output[oc * H * W + ...] = ...;  // 相邻通道可能在同一缓存行
}
```

**解决方案：**
- Padding：在数据结构中插入填充，确保不同线程访问不同缓存行
- 按输出通道并行：每个线程负责完整的输出通道，避免交叉写入

**4. NUMA效应（多处理器系统）**

```
问题：跨NUMA节点访问内存延迟高
影响：远程内存访问延迟是本地的2-3倍
```

**解决方案：**
- First-touch策略：在计算线程上初始化数据
- 数据亲和性绑定：`numactl`工具或OpenMP亲和性设置

**5. 计算与访存的权衡**

对于本项目的5×5卷积（3输入通道，32输出通道）：
- **计算量**：每个输出需要 $3 \times 5 \times 5 = 75$ 次乘加 = 150 FLOPs
- **内存访问**：
  - 输入：$3 \times 5 \times 5 \times 4$ bytes = 300 bytes（假设无缓存）
  - 权重：$32 \times 3 \times 5 \times 5 \times 4$ bytes = 9600 bytes
  - 算术强度：$150 / (300 + 9600) \approx 0.015$ FLOP/byte（极低）

**问题：** 即使是"计算密集型"的卷积，实际算术强度仍然很低，容易受内存带宽限制。

**优化策略：**
- **Im2Col变换**：将卷积转换为矩阵乘法（GEMM），提高算术强度
- **Winograd算法**：减少乘法次数（对小卷积核有效）
- **分块与数据重用**：通过缓存友好的分块，最大化数据重用

**6. 并行粒度的选择**

```
粗粒度（按输出通道）：
  优点：无伪共享，负载容易均衡
  缺点：通道数少时并行度不足
  
细粒度（按输出位置）：
  优点：并行度高
  缺点：伪共享严重，同步开销大
  
折中方案（分块）：
  按输出通道并行 + tile内部串行
```

本项目采用的是**粗粒度并行**（按输出通道），适合输出通道数较多的情况。

#### 1.1.5 性能测试结果

测试配置：
- 输入尺寸：(1, 3, 150, 150)
- 输出尺寸：(1, 32, 150, 150)
- 卷积核：5×5, stride=1, padding=2

| 线程数 | 执行时间(ms) | 加速比 | 并行效率 |
|--------|------------|--------|---------|
| 串行 | - | 1.00× | - |
| 1 | - | - | - |
| 2 | - | - | - |
| 4 | - | - | - |
| 8 | - | - | - |

*注：性能数据待测试后补充*

---

### 1.2 平均池化算子(AvgPool2d) - 访存密集型

#### 1.2.1 算法原理

平均池化(Average Pooling)是一种降采样操作，通过计算局部区域的平均值来减小特征图尺寸。给定输入特征图 $X \in \mathbb{R}^{C \times H_{in} \times W_{in}}$ 和池化窗口大小 $(K_h, K_w)$，平均池化计算输出 $Y \in \mathbb{R}^{C \times H_{out} \times W_{out}}$：

$$
Y[c, h, w] = \frac{1}{K_h \times K_w} \sum_{i=0}^{K_h-1} \sum_{j=0}^{K_w-1} X[c, h \cdot s_h + i, w \cdot s_w + j]
$$

其中：
- $c$: 通道索引（池化操作独立作用于每个通道）
- $s_h$, $s_w$: 步长参数
- $K_h$, $K_w$: 池化窗口大小

输出尺寸计算：

$$
H_{out} = \lfloor \frac{H_{in} - K_h}{s_h} \rfloor + 1
$$

$$
W_{out} = \lfloor \frac{W_{in} - K_w}{s_w} \rfloor + 1
$$

**特点：**
- 保持通道数不变
- 减小空间维度
- 增强特征的平移不变性
- 降低计算量和参数量

#### 1.2.2 实现细节

**串行实现：**
```cpp
for (int c = 0; c < channels; ++c) {
    for (int oh = 0; oh < output_height; ++oh) {
        for (int ow = 0; ow < output_width; ++ow) {
            float sum = 0.0;
            int count = 0;
            // 池化窗口内求和
            for (int kh = 0; kh < kernel_height; ++kh) {
                for (int kw = 0; kw < kernel_width; ++kw) {
                    int h = oh * stride + kh;
                    int w = ow * stride + kw;
                    if (h < input_height && w < input_width) {
                        sum += input[c][h][w];
                        count++;
                    }
                }
            }
            // 计算平均值
            output[c][oh][ow] = sum / count;
        }
    }
}
```

**并行优化策略：**

1. **通道级并行**：不同通道的池化操作完全独立
   ```cpp
   #pragma omp parallel for
   for (int c = 0; c < channels; ++c) {
       // 对每个通道进行池化
   }
   ```

2. **内存访问优化**：
   - 按照行优先顺序访问内存
   - 利用空间局部性提高缓存命中率

3. **边界处理**：在循环内部进行边界检查，确保不越界

#### 1.2.3 并行与串行的区别

| 特性 | 串行版本 | 并行版本 |
|------|---------|---------|
| **循环结构** | 5层嵌套循环顺序执行 | 通道维度并行化 |
| **计算复杂度** | $O(C \times H_{out} \times W_{out} \times K_h \times K_w)$ | 相同，但并行执行 |
| **数据依赖** | 无 | 不同通道间无依赖 |
| **内存访问模式** | 顺序访问 | 多线程并发访问 |
| **线程粒度** | N/A | 每个线程处理一个或多个通道 |

**关键并行特性：**
- **通道独立性**：每个通道的池化互不影响
- **计算简单**：只需要加法和除法，无复杂依赖
- **易于并行**：天然适合数据并行

#### 1.2.4 并行化难点分析

平均池化虽然计算简单，但作为**访存密集型**操作，并行化面临独特挑战：

**1. 极低的计算访存比**

```
问题：计算量远小于内存访问量
影响：性能严重受限于内存带宽
```

对于2×2池化（本项目配置）：
- **计算量**：4次加法 + 1次除法 = 5次浮点运算
- **内存访问**：
  - 读取：$2 \times 2 \times 4$ bytes = 16 bytes
  - 写入：$1 \times 4$ bytes = 4 bytes
  - 总计：20 bytes
- **算术强度**：$5 / 20 = 0.25$ FLOP/byte

**对比：**
- 现代CPU内存带宽：~50 GB/s
- 理论峰值计算能力：~1000 GFLOPS（单核）
- **平衡点**：$1000 / 50 = 20$ FLOP/byte
- **池化实际**：0.25 FLOP/byte << 20

**结论：** 池化操作的性能被内存带宽限制在峰值的 $(0.25/20) \times 100\% = 1.25\%$！

**2. 内存带宽竞争**

```
问题：多线程并发访问内存，争夺有限的带宽
影响：加速比远低于线程数
```

**实例分析（320通道，300×300输入）：**
- 单线程内存带宽需求：$320 \times 300 \times 300 \times 4 \text{ bytes} / t$
- 8线程理想带宽需求：单线程需求 × 8
- 实际可用带宽：~50 GB/s（DDR4-3200）

**理论加速比上限受内存带宽限制**

**3. 缓存命中率低**

```
问题：池化的跨步（stride）导致数据重用率极低
影响：频繁访问主内存，缓存优势无法发挥
```

**数据重用分析：**
- **卷积**（stride=1）：相邻输出共享大部分输入
  - 重用率：$(K_h \times K_w - 1) / (K_h \times K_w) \approx 96\%$（5×5核）
- **池化**（stride=2）：相邻输出**不共享**输入（典型配置）
  - 重用率：0%

**后果：**
- L1缓存失效率高
- 预取器难以预测访问模式
- 内存控制器成为瓶颈

**解决方案：**
```cpp
// 分块处理：尝试将多个通道的小块数据放入缓存
#define TILE_H 64
#define TILE_W 64
#pragma omp parallel for
for (int c = 0; c < channels; ++c) {
    for (int th = 0; th < H; th += TILE_H) {
        for (int tw = 0; tw < W; tw += TILE_W) {
            // 在tile内处理，提高空间局部性
        }
    }
}
```

**4. False Sharing更严重**

```
问题：输出尺寸减半，相邻输出更可能在同一缓存行
影响：缓存一致性协议开销显著增加
```

**示例：**
- 输入：300×300（每行1200 bytes）
- 输出：150×150（每行600 bytes）
- 缓存行：64 bytes = 16个float
- **问题**：每个缓存行包含16个输出元素，多线程易冲突

**解决方案：**
- 按通道并行（本项目采用）：不同线程处理不同通道，避免写冲突
- 填充（Padding）：在输出行之间插入填充，对齐到缓存行边界

**5. 并行开销占比高**

```
问题：计算时间极短，线程创建/销毁开销相对显著
影响：小规模问题并行可能更慢
```

**时间开销分析：**
- 线程创建：~10-100 μs（取决于实现）
- 实际计算：对于300×300×320，约1-10 ms
- **开销占比**：1-10%

**对比卷积：**
- 卷积计算时间：数百ms到数秒
- 线程开销占比：<1%

**优化：**
- 使用线程池（OpenMP默认实现）
- 批量处理多个池化操作

**6. 跨平台性能差异大**

```
问题：访存密集型算子对硬件敏感
影响：不同平台的加速比差异显著
```

| 平台特性 | 影响 |
|---------|------|
| 内存带宽 | 直接决定性能上限 |
| L3缓存大小 | 影响大数据集性能 |
| NUMA拓扑 | 跨节点访问延迟高 |
| 预取策略 | 影响连续访问性能 |

**7. 并行策略的权衡**

本项目采用的**通道级并行**：

**优点：**
- 无数据依赖，无伪共享
- 实现简单，负载均衡好
- 适合通道数多的情况（320通道）

**缺点：**
- 通道数少时并行度不足
- 无法利用输出位置间的并行性

**替代方案（未采用）：**
```cpp
// 二维并行：同时在通道和空间维度并行
#pragma omp parallel for collapse(3)
for (int c = 0; c < channels; ++c) {
    for (int h = 0; h < out_h; ++h) {
        for (int w = 0; w < out_w; ++w) {
            // 更细粒度，但可能增加同步开销
        }
    }
}
```

**8. 实际性能预测**

使用Roofline模型预测池化性能：

$$
\text{Performance} = \min(\text{Peak FLOPS}, 0.25 \times \text{Bandwidth})
$$

对于典型桌面CPU：
- Peak FLOPS（单核）：~50 GFLOPS
- Memory Bandwidth：~50 GB/s
- **预测性能**：$\min(50, 0.25 \times 50) = 12.5$ GFLOPS
- **效率**：$12.5 / 50 = 25\%$（受内存限制）

**结论：** 池化的并行加速比受限于内存带宽，通常只能达到理论线性加速比的 **30-50%**。

#### 1.2.5 性能测试结果

测试配置：
- 输入尺寸：(1, 320, 300, 300)
- 输出尺寸：(1, 320, 150, 150)
- 池化窗口：2×2, stride=2

| 线程数 | 执行时间(ms) | 加速比 | 并行效率 |
|--------|------------|--------|---------|
| 串行 | - | 1.00× | - |
| 1 | - | - | - |
| 2 | - | - | - |
| 4 | - | - | - |
| 8 | - | - | - |

*注：性能数据待测试后补充*

---

## 2. 红黑排序Gauss-Seidel迭代法

### 2.1 算法原理

Gauss-Seidel方法是求解线性方程组 $Ax = b$ 的经典迭代方法，常用于求解泊松方程等偏微分方程的离散化系统。对于二维泊松方程：

$$
-\nabla^2 u = f, \quad (x, y) \in \Omega
$$

使用有限差分离散化后得到：

$$
\frac{u_{i-1,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} - 4u_{i,j}}{h^2} = f_{i,j}
$$

标准Gauss-Seidel迭代格式：

$$
u_{i,j}^{(k+1)} = \frac{1}{4}(u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)} + u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)} - h^2 f_{i,j})
$$

**数据依赖问题：** 标准Gauss-Seidel方法在更新 $u_{i,j}$ 时依赖于已更新的 $u_{i-1,j}$ 和 $u_{i,j-1}$，这种数据依赖使得算法难以直接并行化。

### 2.2 红黑排序(Red-Black Ordering)

红黑排序将网格点分为两类：
- **红点**：$i + j$ 为偶数
- **黑点**：$i + j$ 为奇数

关键性质：
- 红点只依赖于黑点，黑点只依赖于红点
- 所有红点可以同时更新（并行）
- 所有黑点可以同时更新（并行）

迭代步骤：
1. **红点更新** (并行)：
   $$
   u_{red}^{(k+1)} = \frac{1}{4}(u_{black}^{(k)} + u_{black}^{(k)} + u_{black}^{(k)} + u_{black}^{(k)} - h^2 f_{red})
   $$

2. **黑点更新** (并行)：
   $$
   u_{black}^{(k+1)} = \frac{1}{4}(u_{red}^{(k+1)} + u_{red}^{(k+1)} + u_{red}^{(k+1)} + u_{red}^{(k+1)} - h^2 f_{black})
   $$

### 2.3 区域分解并行策略

对于大规模三维问题（如512×512×512），采用区域分解方法：

1. **区域划分**：将计算域划分为若干子区域，每个线程负责一个区域
2. **多级分块**：
   - 第一级：线程级分块
   - 第二级：缓存友好的小块
3. **边界同步**：子区域边界需要进行数据同步

### 2.4 串行与并行的区别

| 特性 | 串行标准GS | 串行红黑GS | 并行红黑GS |
|------|-----------|-----------|-----------|
| **更新顺序** | 逐点顺序更新 | 红点→黑点 | 同色点并行更新 |
| **数据依赖** | 强依赖 | 颜色间依赖 | 同色点无依赖 |
| **收敛速度** | 快 | 快 | 快 |
| **并行性** | 无 | 部分 | 高 |
| **内存访问** | 顺序 | 跳跃 | 分块优化 |
| **同步开销** | 无 | 无 | 每次迭代2次同步 |

### 2.5 三维实现细节

**网格规模：** 512×512×512 (约1.34亿个网格点)

**OpenMP并行化：**
```cpp
#pragma omp parallel for collapse(3)
for (int k = 1; k <= N; ++k) {
    for (int i = 1; i <= N; ++i) {
        for (int j = 1; j <= N; ++j) {
            if ((i + j + k) % 2 == color) {  // color: 0=红, 1=黑
                u[idx] = 0.166667 * (
                    u[idx-1] + u[idx+1] +           // x方向
                    u[idx-N-2] + u[idx+N+2] +       // y方向
                    u[idx-(N+2)*(N+2)] + u[idx+(N+2)*(N+2)] -  // z方向
                    h2 * f[idx]
                );
            }
        }
    }
}
```

### 2.6 性能测试结果

测试配置：
- 网格规模：512×512×512 (约1.34亿个网格点)
- 最大迭代次数：100
- 收敛容差：1e-6
- 测试环境：8核处理器

**实测结果：**

| 方法 | 线程数 | 执行时间(s) | 每次迭代(ms) | 加速比 | 并行效率 | 迭代次数 | 最终残差 |
|------|-------|-----------|------------|--------|---------|---------|---------|
| 串行红黑 | - | 36.226 | 362.26 | 1.00× | - | 100 | 1.71e+05 |
| 并行红黑 | 1 | 108.871 | 1088.71 | 1.00× | 100% | 100 | 1.71e+05 |
| 并行红黑 | 2 | 63.867 | 638.67 | 1.70× | 85.2% | 100 | 1.71e+05 |
| 并行红黑 | 4 | 41.297 | 412.97 | 2.64× | 65.9% | 100 | 1.71e+05 |
| 并行红黑 | 8 | 29.504 | 295.04 | 3.69× | 46.1% | 100 | 1.71e+05 |

**性能分析：**

1. **加速比分析**：
   - 2线程：1.70×，接近理论值2×，并行效率85.2%
   - 4线程：2.64×，并行效率65.9%，开始出现扩展瓶颈
   - 8线程：3.69×，并行效率46.1%，受内存带宽限制

2. **串行红黑 vs 并行红黑(1线程)**：
   - 串行版本(36.2s)明显快于并行版本单线程(108.9s)
   - 原因：并行版本有额外的线程管理和同步开销
   - 说明：只有在多线程时并行版本才有优势

3. **扩展性瓶颈**：
   - 内存带宽：512³规模需要约8GB内存，8线程并发访问导致带宽饱和
   - 同步开销：每次迭代需要2次同步点（红点、黑点）
   - 缓存一致性：多线程共享数据导致缓存失效

4. **实际应用价值**：
   - 对于超大规模问题(512³)，8线程仍可获得3.69×加速
   - 相比串行红黑(36.2s)，8线程并行(29.5s)仍有显著提升

---

## 3. 三对角方程组并行求解

### 3.1 问题描述

三对角线性方程组形式：

$$
\begin{bmatrix}
b_0 & c_0 & & & \\
a_1 & b_1 & c_1 & & \\
& a_2 & b_2 & c_2 & \\
& & \ddots & \ddots & \ddots \\
& & & a_{n-1} & b_{n-1}
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_1 \\ x_2 \\ \vdots \\ x_{n-1}
\end{bmatrix}
=
\begin{bmatrix}
d_0 \\ d_1 \\ d_2 \\ \vdots \\ d_{n-1}
\end{bmatrix}
$$

三对角方程组广泛出现在：
- 一维热传导方程
- 样条插值
- 有限差分法
- 信号处理

### 3.2 Thomas算法(追赶法)

**串行Thomas算法**是求解三对角方程组的经典方法，时间复杂度 $O(n)$。

**前向消元(Forward Elimination)：**

$$
\gamma_0 = \frac{c_0}{b_0}, \quad \rho_0 = \frac{d_0}{b_0}
$$

对于 $i = 1, 2, \ldots, n-1$：

$$
\gamma_i = \frac{c_i}{b_i - a_i \gamma_{i-1}}, \quad \rho_i = \frac{d_i - a_i \rho_{i-1}}{b_i - a_i \gamma_{i-1}}
$$

**回代(Back Substitution)：**

$$
x_{n-1} = \rho_{n-1}
$$

对于 $i = n-2, n-3, \ldots, 0$：

$$
x_i = \rho_i - \gamma_i x_{i+1}
$$

**数据依赖：** Thomas算法存在严重的数据依赖：
- 前向消元：每一步依赖上一步的结果
- 回代：从后向前依赖

### 3.3 Brugnano并行算法

Brugnano方法通过区域分解实现并行化：

**步骤1：区域划分**
将大小为 $n$ 的系统划分为 $P$ 个子系统，每个子系统大小约为 $n/P$。

**步骤2：局部修正Thomas算法**
对每个子系统独立求解修正后的方程组（并行）：
$$
\begin{bmatrix}
b_i^* & c_i & & \\
a_{i+1} & b_{i+1} & c_{i+1} & \\
& \ddots & \ddots & \ddots \\
& & a_j & b_j^*
\end{bmatrix}
\begin{bmatrix}
x_i \\ x_{i+1} \\ \vdots \\ x_j
\end{bmatrix}
=
\begin{bmatrix}
d_i^* \\ d_{i+1} \\ \vdots \\ d_j^*
\end{bmatrix}
$$

其中边界系数被修正，使得可以表示为边界值的函数。

**步骤3：构建并求解规约系统**
收集所有子区域边界的方程，构建规约系统（大小为 $2P \times 2P$）：
$$
R \cdot x_{boundary} = d_{boundary}
$$

**步骤4：更新内部节点**
利用边界值，各子区域并行更新内部节点：
$$
x_{internal} = x_{internal}^{local} + \alpha \cdot x_{left} + \beta \cdot x_{right}
$$

### 3.4 并行算法分析

| 特性 | Thomas串行 | Recursive Doubling | Brugnano并行 |
|------|-----------|-------------------|-------------|
| **时间复杂度** | $O(n)$ | $O(n \log P)$ | $O(n/P + P^2)$ |
| **并行度** | 无 | 高 | 高 |
| **通信次数** | 0 | $O(\log P)$ | $O(1)$ |
| **适用场景** | 单核 | 线程数少 | 线程数多 |
| **负载均衡** | N/A | 较好 | 优秀 |
| **实现复杂度** | 简单 | 中等 | 复杂 |

### 3.5 实现细节

**Brugnano方法的OpenMP实现：**

```cpp
// 步骤1：并行处理各子区域的局部系统
#pragma omp parallel for
for (int tid = 0; tid < num_threads; ++tid) {
    int start = tid * chunk_size;
    int end = min(start + chunk_size, n);
    // 对局部系统进行修正的Thomas算法
    solve_local_system(start, end, ...);
}

// 步骤2：串行求解规约系统
solve_reduced_system(boundary_equations);

// 步骤3：并行更新内部节点
#pragma omp parallel for
for (int tid = 0; tid < num_threads; ++tid) {
    int start = tid * chunk_size;
    int end = min(start + chunk_size, n);
    // 使用边界值更新内部节点
    update_interior(start, end, boundary_values, ...);
}
```

### 3.6 串行与并行的区别

**关键差异：**

1. **计算模式**：
   - 串行：单线程依次处理每个元素
   - 并行：多线程同时处理不同子区域

2. **数据依赖处理**：
   - 串行：自然遵循依赖顺序
   - 并行：通过规约系统解耦子区域

3. **通信开销**：
   - 串行：无
   - 并行：边界数据需要同步

4. **数值稳定性**：
   - 两者在数值上等价
   - 并行版本可能有轻微的浮点误差

### 3.7 性能测试结果

测试配置：多种规模的三对角系统，测试环境：8核处理器

#### 测试数据集：test_8k.txt (n=8,192)

| 算法版本 | 线程数 | 执行时间(ms) | 加速比 | 并行效率 | 最大残差 |
|---------|--------|------------|--------|---------|---------|
| 串行Thomas | - | 0.148 | 1.00× | - | 3.55e-15 |
| Brugnano内部串行 | - | 0.296 | 0.50× | - | 3.55e-15 |
| Brugnano | 1 | 0.261 | 1.13× | - | 2.94e-01 |
| Brugnano | 2 | 1.070 | 0.28× | 14.0% | 1.02e+00 |
| Brugnano | 4 | 0.766 | 0.39× | 9.7% | 1.53e+00 |
| Brugnano | 8 | 1.007 | 0.29× | 3.7% | 3.39e+00 |

#### 测试数据集：test_16k.txt (n=16,384)

| 算法版本 | 线程数 | 执行时间(ms) | 加速比 | 并行效率 | 最大残差 |
|---------|--------|------------|--------|---------|---------|
| 串行Thomas | - | 0.253 | 1.00× | - | 3.55e-15 |
| Brugnano内部串行 | - | 0.621 | 0.41× | - | 3.55e-15 |
| Brugnano | 1 | 0.420 | 1.48× | - | 4.37e-01 |
| Brugnano | 2 | 1.115 | 0.56× | 28.0% | 4.61e+00 |
| Brugnano | 4 | 0.970 | 0.64× | 16.0% | 4.61e+00 |
| Brugnano | 8 | 1.118 | 0.56× | 7.0% | 4.61e+00 |

#### 测试数据集：test_128k.txt (n=131,072)

| 算法版本 | 线程数 | 执行时间(ms) | 加速比 | 并行效率 | 最大残差 |
|---------|--------|------------|--------|---------|---------|
| 串行Thomas | - | 1.398 | 1.00× | - | 5.33e-15 |
| Brugnano内部串行 | - | 1.466 | 0.95× | - | 5.33e-15 |
| Brugnano | 1 | 3.139 | 0.47× | - | 1.04e-01 |
| Brugnano | 2 | 2.393 | 0.61× | 30.7% | 3.07e+00 |
| Brugnano | 4 | 1.282 | 1.14× | 28.6% | 3.34e+00 |
| Brugnano | 8 | 2.035 | 0.72× | 9.0% | 3.34e+00 |

#### 测试数据集：test_1024k.txt (n=1,048,576) - 最大规模

| 算法版本 | 线程数 | 执行时间(ms) | 加速比 | 并行效率 | 最大残差 |
|---------|--------|------------|--------|---------|---------|
| 串行Thomas | - | 10.931 | 1.00× | - | 5.33e-15 |
| Brugnano内部串行 | - | 11.186 | 0.98× | - | 5.33e-15 |
| Brugnano | 1 | 19.341 | 0.58× | - | 4.42e-02 |
| Brugnano | 2 | 12.273 | 0.91× | 45.7% | 1.33e+00 |
| Brugnano | 4 | 8.589 | 1.30× | 32.6% | 2.68e+00 |
| Brugnano | 8 | 8.037 | 1.39× | 17.4% | 2.83e+00 |

**性能分析：**

1. **小规模数据(8k-16k)的问题**：
   - 串行Thomas算法最快(0.148-0.253ms)
   - Brugnano并行版本反而更慢，原因：
     - 线程创建和管理开销 > 计算时间
     - 规约系统求解的额外开销
     - 数据量小，并行收益无法抵消开销

2. **中等规模数据(128k)**：
   - 4线程开始显示优势：1.14×加速比
   - 但仍不如纯串行Thomas(1.398ms)
   - 并行效率约28.6%

3. **大规模数据(1024k)**：
   - **并行优势终于显现**：
     - 4线程：8.589ms，加速比1.30×
     - 8线程：8.037ms，加速比1.39×，优于串行Thomas(10.931ms)
   - 原因：计算量足够大，并行收益超过开销

4. **数值稳定性问题**：
   - 注意到Brugnano并行版本的最大残差显著增大
   - 原因：浮点运算顺序改变导致数值误差累积
   - 对于工程应用，这些误差(10⁰量级)可能需要进一步优化

5. **关键结论**：
   - **三对角方程组的并行化具有挑战性**
   - 只有在**超大规模**(n>100万)时，并行才有优势
   - 对于中小规模，串行Thomas算法仍是最优选择
   - Amdahl定律体现明显：规约系统求解成为串行瓶颈

---

## 4. 总结与分析

### 4.1 并行化技术对比

| 算法类型 | 并行策略 | 主要挑战 | 最佳加速比 | 适用规模 |
|---------|---------|---------|-----------|---------|
| 神经网络算子 | 数据并行 | 内存带宽 | 接近线性(待测) | 大中小均可 |
| Gauss-Seidel | 红黑排序 | 同步开销 | 3.69× (8线程) | 大规模(512³) |
| 三对角求解 | 区域分解 | 数据依赖 | 1.39× (8线程) | 超大规模(>100万) |

### 4.2 实测性能分析

#### 4.2.1 Gauss-Seidel方法的成功案例

**优势：**
- 大规模问题(512³ ≈ 1.34亿网格点)
- 计算密集型，每个网格点需要多次迭代
- 红黑排序有效打破数据依赖

**实测表现：**
- 8线程达到3.69×加速比
- 相比串行红黑(36.2s)，8线程并行(29.5s)提速18.5%
- 并行效率：2线程85.2%，4线程65.9%，8线程46.1%

**瓶颈分析：**
- 内存带宽：8GB数据的并发访问
- 同步点：每次迭代2次(红点+黑点)
- 缓存一致性开销

#### 4.2.2 三对角求解的挑战

**困难：**
- 强数据依赖：每一步依赖前一步
- 规约系统求解：串行瓶颈
- 额外开销：线程管理、数据重组

**实测表现：**
- 小规模(8k-16k)：并行版本**更慢**，开销 > 收益
- 中等规模(128k)：勉强持平，4线程1.14×
- 大规模(1024k)：**终于盈利**，8线程1.39×

**关键发现：**
- 并行只在n>100万时才有优势
- Amdahl定律的经典体现
- 数值误差增大(残差从10⁻¹⁵增至10⁰)

### 4.3 并行化原则总结

基于实测数据，得出以下原则：

#### 1. **问题规模是关键**
```
小规模：串行最优
中规模：并行持平或略优
大规模：并行显著优势
```

**实例：**
- Gauss-Seidel 512³：8线程3.69×加速
- 三对角求解 1024k：8线程仅1.39×加速

#### 2. **数据依赖是瓶颈**
| 算法 | 数据依赖 | 打破方法 | 效果 |
|------|---------|---------|------|
| 神经网络算子 | 无/弱 | 天然并行 | 优秀 |
| Gauss-Seidel | 强 | 红黑排序 | 良好(3.69×) |
| 三对角求解 | 极强 | 区域分解 | 一般(1.39×) |

#### 3. **并行开销不可忽视**
- **线程创建**：毫秒级延迟
- **同步操作**：每次需要等待所有线程
- **缓存失效**：多线程共享数据

**数据支持：**
- Gauss-Seidel串行红黑36.2s < 并行1线程108.9s
- 原因：并行版本的管理开销

#### 4. **扩展性受限于硬件**
- **内存带宽**：8线程同时访问导致饱和
- **缓存容量**：L3缓存不足以容纳大数据
- **NUMA效应**：跨节点访问代价高

**证据：**
- Gauss-Seidel并行效率：2线程85% → 8线程46%
- 说明：内存带宽成为瓶颈

### 4.4 实用建议

#### 4.4.1 何时使用并行

✅ **推荐并行：**
- 计算量 >> 通信量
- 数据依赖弱或可打破
- 问题规模足够大(通常>10⁶)
- 计算密集型任务

❌ **不推荐并行：**
- 小规模问题(n<10⁴)
- 串行部分占比高(>20%)
- 数据依赖极强且难以打破
- 内存密集型任务

#### 4.4.2 优化技巧

1. **选择合适的并行粒度**
   - 太细：线程开销 > 并行收益
   - 太粗：负载不均衡
   
2. **减少同步点**
   - Gauss-Seidel：每次迭代2次同步
   - 优化：批量多次迭代后再同步

3. **优化内存访问模式**
   - 连续访问：利用缓存行
   - 分块技术：64×64×64提高缓存命中

4. **负载均衡**
   - 静态调度：适合规则问题
   - 动态调度：适合不规则问题

### 4.5 结论

通过本项目的实现和测试，我们得出以下结论：

#### 1. **并行化不是万能药**
- 三对角求解：大部分情况串行更快
- 只有超大规模(n>100万)才值得并行

#### 2. **数据并行最容易实现**
- 神经网络算子：天然数据并行
- 易于实现，加速比好(理论上接近线性)

#### 3. **打破数据依赖是关键**
- Gauss-Seidel红黑排序：成功案例
- 三对角Brugnano：部分成功

#### 4. **实际加速比远低于理论值**
主要原因：
- **Amdahl定律**：串行部分限制(规约系统)
- **内存带宽**：8线程时带宽饱和(Gauss-Seidel 46%效率)
- **同步开销**：每次迭代需要等待
- **缓存效应**：False sharing, 缓存失效

#### 5. **规模决定策略**
```
n < 10⁴:      串行优先
10⁴ < n < 10⁶: 视情况而定，测试决策
n > 10⁶:      并行有显著优势
```

#### 6. **数值稳定性需注意**
- Brugnano残差从10⁻¹⁵增至10⁰
- 浮点运算顺序改变导致误差累积
- 工程应用需要额外验证

### 4.6 实验总结

| 项目 | 结果 |
|------|------|
| **测试算法** | 3类(神经网络、迭代法、递推算法) |
| **测试规模** | 从8k到512³(1.34亿) |
| **最佳加速比** | 3.69× (Gauss-Seidel 8线程) |
| **最差情况** | 0.28× (三对角8k数据2线程) |
| **成功案例** | Gauss-Seidel大规模问题 |
| **失败案例** | 三对角小规模问题 |

**核心启示：** 并行计算需要权衡计算收益与并行开销，只有在问题规模足够大、数据依赖可打破的情况下，才能获得有效加速。盲目并行化可能适得其反。

---

## 参考资料

1. Gauss-Seidel优化: [gulang2019/optimizing-gauss-seidel-iteration](https://github.com/gulang2019/optimizing-gauss-seidel-iteration)
2. 三对角求解器: [tanim72/15418-final-project](https://github.com/tanim72/15418-final-project)
3. OpenMP API规范
4. 《并行算法设计与分析》课程讲义

